{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSDA-f8SAgC4",
        "outputId": "1f7bb913-4256-4cc7-f8a1-a26f1ac33f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets==3.2.0 in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (3.13.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.2.0) (6.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.2.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.2.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.2.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.2.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.2.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.2.0) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.0->datasets==3.2.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.2.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.2.0) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.2.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.2.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.12/dist-packages (2.5.1)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.12/dist-packages (0.92)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.57.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.12/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: sphinx-argparse in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (0.5.2)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (3.0.2)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.12/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"datasets==3.2.0\"\n",
        "!pip install -U \"evaluate\" \"transformers\" \"sentencepiece\"\n",
        "!pip install bert-score sacrebleu rouge-score sumy indic-nlp-library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "i3XEF9XjX3uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import nltk\n",
        "from datasets import load_dataset\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bert_scorer\n",
        "from sacrebleu.metrics import CHRF\n"
      ],
      "metadata": {
        "id": "vTyCJK01AogW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiYV9zxzBzlP",
        "outputId": "aaf7b8d0-4899-4338-f188-7ec3090ca500"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "EeJOoPFeYE_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TELUGU_STOPWORDS = {'మరుగు','లో','కు','ఈ','అని','ది','తో','కోసం','ఇది','వద్ద','పై','అది'}\n",
        "ENGLISH_STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_bilingual_text(text):\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[“”‘’\"\\'’]', '', text)\n",
        "    text = re.sub(r'([?.!,])', r' \\1 ', text)\n",
        "    tokens = indic_tokenize.trivial_tokenize(text)\n",
        "\n",
        "    telugu_tokens, english_tokens = [], []\n",
        "\n",
        "    for token in tokens:\n",
        "        if re.search(r'[\\u0C00-\\u0C7F]', token):\n",
        "            if token not in TELUGU_STOPWORDS:\n",
        "                telugu_tokens.append(token)\n",
        "        else:\n",
        "            token = token.lower()\n",
        "            if token not in ENGLISH_STOPWORDS:\n",
        "                english_tokens.append(token)\n",
        "\n",
        "    return ' '.join(telugu_tokens + english_tokens)\n"
      ],
      "metadata": {
        "id": "NN0NO4h7AqB6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "nl7TDvU7YO3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"csebuetnlp/xlsum\", \"telugu\")\n",
        "\n",
        "sample = dataset['train'][0]\n",
        "original_text = sample['text']\n",
        "reference_summary_te = sample['summary']\n",
        "\n",
        "print(\"Original (Telugu):\", original_text[:300])\n",
        "cleaned_text = preprocess_bilingual_text(original_text)\n",
        "print(\"\\nCleaned bilingual (extractive use only):\", cleaned_text[:300])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRNdMvmWArg5",
        "outputId": "4db38fe2-6158-4bf5-b099-7ea9a3f9738b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original (Telugu): అయితే, ఆ జాబితా తప్పులతడకని పైలట్లు అంటున్నారు. విమర్శలు రావడంతో లైసెన్సులు నకిలీవి కాదని, పరీక్ష ప్రక్రియలో లోపోలున్నాయని ప్రభుత్వం పేర్కొంది. ఇమ్రాన్‌ఖాన్ ప్రభుత్వం దిద్దుబాటు చర్యలు తీసుకుంటుండగా.. లైసెన్స్ స్కామ్‌తో సంబంధం ఉన్న వారిపై చర్యలు తీసుకోవాలని సుప్రీంకోర్టు ఆదేశించింది. బీబీసీ ప్రతినిధ\n",
            "\n",
            "Cleaned bilingual (extractive use only): అయితే ఆ జాబితా తప్పులతడకని పైలట్లు అంటున్నారు విమర్శలు రావడంతో లైసెన్సులు నకిలీవి కాదని పరీక్ష ప్రక్రియలో లోపోలున్నాయని ప్రభుత్వం పేర్కొంది ఇమ్రాన్‌ఖాన్ ప్రభుత్వం దిద్దుబాటు చర్యలు తీసుకుంటుండగా లైసెన్స్ స్కామ్‌తో సంబంధం ఉన్న వారిపై చర్యలు తీసుకోవాలని సుప్రీంకోర్టు ఆదేశించింది బీబీసీ ప్రతినిధి షుమాయ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extractive Summaries"
      ],
      "metadata": {
        "id": "BwXqucPXYYi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-based extractive"
      ],
      "metadata": {
        "id": "d-pJ3catYaTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_extractive_summary(text, top_k=3):\n",
        "    sentences = re.split(r'(?<=[\\\\.।])\\s+', text)\n",
        "    if len(sentences) == 1:\n",
        "        sentences = text.split('. ')\n",
        "    tokens = [w for s in sentences for w in s.split()]\n",
        "    freq = {}\n",
        "    for t in tokens:\n",
        "        freq[t] = freq.get(t, 0) + 1\n",
        "\n",
        "    maxf = max(freq.values()) if freq else 1\n",
        "    for k in freq:\n",
        "        freq[k] /= maxf\n",
        "\n",
        "    sent_scores = [(s, sum(freq.get(w,0) for w in s.split())) for s in sentences]\n",
        "    top = sorted(sent_scores, key=lambda x:x[1], reverse=True)[:top_k]\n",
        "    summary = ' '.join(s[0].strip() for s in sorted(top, key=lambda x:sentences.index(x[0])))\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "N0Y8A31TAt1t"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextRank"
      ],
      "metadata": {
        "id": "8BortCNQYkAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def textrank_summary(text, sentence_count=3):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer('english'))\n",
        "    summarizer = TextRankSummarizer()\n",
        "    summary_sentences = summarizer(parser.document, sentence_count)\n",
        "    return ' '.join(str(s) for s in summary_sentences)\n"
      ],
      "metadata": {
        "id": "23tEnsLyAvi-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load multilingual mT5 model , Translation Model\n",
        "# Creating Translation Pipeline"
      ],
      "metadata": {
        "id": "8IvwTVhoYoLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device =\", device)\n",
        "\n",
        "# Telugu Summarization model\n",
        "summ_model_name = \"csebuetnlp/mT5_multilingual_xlsum\"\n",
        "summ_tokenizer = AutoTokenizer.from_pretrained(summ_model_name)\n",
        "summ_model = AutoModelForSeq2SeqLM.from_pretrained(summ_model_name).to(device)\n",
        "\n",
        "# Translation model NLLB\n",
        "tran_model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "tran_tokenizer = AutoTokenizer.from_pretrained(tran_model_name)\n",
        "tran_model = AutoModelForSeq2SeqLM.from_pretrained(tran_model_name).to(device)\n",
        "\n",
        "translator = pipeline(\n",
        "    \"translation\",\n",
        "    model=tran_model,\n",
        "    tokenizer=tran_tokenizer,\n",
        "    src_lang=\"tel_Telu\",\n",
        "    tgt_lang=\"eng_Latn\",\n",
        "    device=0 if device == \"cuda\" else -1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaROER3JA0Hn",
        "outputId": "5ad507eb-b80f-468e-85b3-da4404b6d44d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device = cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Abstractive Summary"
      ],
      "metadata": {
        "id": "nSxQarTtY7qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_telugu_summary(text):\n",
        "    inputs = summ_tokenizer(text, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    summary_ids = summ_model.generate(inputs[\"input_ids\"], max_length=60, min_length=10)\n",
        "    return summ_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "telugu_summary = generate_telugu_summary(original_text)\n",
        "print(\"\\n Telugu Summary:\", telugu_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSNpteM7A16t",
        "outputId": "2583d13f-cd2c-41e6-8505-0c1d14ff7457"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Telugu Summary: పాకిస్తాన్ ప్రధాని ఇమ్రాన్ ఖాన్ ప్రభుత్వం ఇటీవల జారీ చేసిన లైసెన్స్ పరీక్షల జాబితాపై తీవ్ర విమర్శలు వెల్లువెత్తాయి.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translate Summary to English and Reference Summary"
      ],
      "metadata": {
        "id": "ySyT-CSUY_W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "english_summary = translator(telugu_summary)[0]['translation_text']\n",
        "print(\"\\n English Summary:\", english_summary)\n",
        "\n",
        "reference_summary_en = translator(reference_summary_te)[0][\"translation_text\"]\n",
        "print(\"\\n Reference English Summary:\", reference_summary_en)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3M6Uwa-Exlc",
        "outputId": "e82d0272-4bd3-43c0-c2df-d868897e2bf5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " English Summary: The recent list of licensure examinations issued by the government of Prime Minister Imran Khan of Pakistan has been heavily criticized.\n",
            "\n",
            " Reference English Summary: A new crisis has begun in Pakistan's aviation industry, with the airline's own aviation minister releasing a list of 262 pilots with fake licenses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# BERTScore and ChrF Score"
      ],
      "metadata": {
        "id": "BkEhlurAZIGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "P, R, F1 = bert_scorer([english_summary], [reference_summary_en], lang=\"en\")\n",
        "print(\"\\n BERTScore F1:\", float(F1[0]))\n",
        "\n",
        "chrf = CHRF()\n",
        "chrf_score = chrf.sentence_score(english_summary, [reference_summary_en])\n",
        "print(\"\\n ChrF Score:\", chrf_score.score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEfrBKlgZHvD",
        "outputId": "7601d176-b2a8-4a1a-f320-5e76826c9181"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " BERTScore F1: 0.8884020447731018\n",
            "\n",
            " ChrF Score: 28.88525305218867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "XKmjHdV4Wq54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Telugu long text\n",
        "telugu_text = \"\"\"\n",
        "పాకిస్తాన్ విమానాయాన రంగంలో భారీ వివాదం చెలరేగింది.పాకిస్తాన్ ప్రభుత్వ ప్రకటన ప్రకారం దేశంలోని 860 మంది పైలట్లలో 262 మంది పైలట్లు నకిలీ లైసెన్సులు కలిగి ఉన్నట్లు ఆరోపణలు వచ్చాయి.\n",
        "ఈ విషయంపై పార్లమెంట్‌లో షాక్‌కు గురిచేసే వివరాలు వెల్లడికాగా ప్రముఖ ఎయిర్‌లైన్లలో పనిచేస్తున్న పలు పైలట్లు పరీక్షలు రాయకుండాలైసెన్సులు పొందినట్లు సమాచారం.ఈ ఘటన ప్రపంచవ్యాప్తంగా విమానయాన భద్రతపై తీవ్ర ఆందోళనను రేపుతోంది.\n",
        "\"\"\"\n",
        "\n",
        "# ✅ Telugu reference summary\n",
        "ref_telugu_summary = \"\"\"\n",
        "పాకిస్తాన్‌లో 262 మంది పైలట్లు నకిలీ లైసెన్సులు కలిగి ఉన్నారని ఆరోపణలు రావడంతో విమానయాన రంగంలో భారీ వివాదం చెలరేగింది.\n",
        "\"\"\"\n",
        "\n",
        "# ✅ English reference summary\n",
        "ref_english_summary = \"\"\"\n",
        "A major controversy erupted in Pakistan after allegations surfaced that 262 pilots\n",
        "held fake licenses, causing global concern over aviation safety.\n",
        "\"\"\"\n",
        "\n",
        "generated_telugu_summary = generate_telugu_summary(telugu_text)\n",
        "generated_english_summary = translator(generated_telugu_summary)[0]['translation_text']\n",
        "\n",
        "print(\"Generated Telugu Summary:\", generated_telugu_summary)\n",
        "print(\"Generated English Summary:\", generated_english_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCmCWGv9WqmA",
        "outputId": "7e7b8425-b8bc-40d3-c3ee-593630fc8a1a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Telugu Summary: పాకిస్తాన్ విమానయాన రంగంలో నకిలీ లైసెన్సులు కలిగి ఉన్నట్లు ఆరోపణలు ఎదుర్కొంటున్న పైలట్ల వివరాలను పార్లమెంట్ లో వెల్లడించింది.\n",
            "Generated English Summary: The Parliament has unveiled details of pilots facing allegations of having fake licenses in Pakistan's aviation sector.\n"
          ]
        }
      ]
    }
  ]
}